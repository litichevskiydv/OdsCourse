{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.1\n",
      "sklearn 0.19.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.9.75-linuxkit-aufs\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   : a9eafcf5743bade7bfe77c9d9bf128931780e9a4\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python', 'c++', 'android', 'java', 'c#', 'ios', 'javascript', 'php', 'html', 'jquery'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "\n",
    "Ответ 2:  $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$\n",
    "\n",
    "Ответ 2: $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    sigma = (1.0 / (1.0 + np.exp(-z))) if z >= 0 else (1.0 - 1.0 / (1.0 + np.exp(z)))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    sample_loss += -(np.log(np.maximum(sigma, tolerance)) if y == 1 else np.log(np.maximum(1.0 - sigma, tolerance)))\n",
    "                 \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71f28aa806646fbb843b0b35f66a64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6514fa4be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 19.76\n",
      "Ответ 3, ближе всего к 19.74\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))\n",
    "print('Ответ 3, ближе всего к 19.74')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        n = 0\n",
    "        self._loss = []\n",
    "        accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                actual_tags = []\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    sigma = (1.0 / (1.0 + np.exp(-z))) if z >= 0 else (1.0 - 1.0 / (1.0 + np.exp(z)))\n",
    "                    if sigma > 0.9:\n",
    "                        actual_tags.append(tag)\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    sample_loss += -(np.log(np.maximum(sigma, tolerance)) if y == 1 else np.log(np.maximum(1.0 - sigma, tolerance)))\n",
    "                 \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracy.append(len(set(actual_tags).intersection(tags)) / len(set(actual_tags).union(tags)))\n",
    "                self._loss.append(sample_loss)\n",
    "                n += 1\n",
    "                \n",
    "        return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e277c3f4be3e40f9aa2818ee761dade2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        n = 0\n",
    "        self._loss = []\n",
    "        accuracy = []\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                actual_tags = []\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    sigma = (1.0 / (1.0 + np.exp(-z))) if z >= 0 else (1.0 - 1.0 / (1.0 + np.exp(z)))\n",
    "                    if sigma > 0.9:\n",
    "                        actual_tags.append(tag)\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    sample_loss += -(np.log(np.maximum(sigma, tolerance)) if y == 1 else np.log(np.maximum(1.0 - sigma, tolerance)))\n",
    "                 \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        processed_words = set()\n",
    "                        for word in sentence:  \n",
    "                            if word not in processed_words:\n",
    "                                processed_words.add(word)\n",
    "                                self._w[tag][self._vocab[word]] -= learning_rate*lmbda*self._w[tag][self._vocab[word]]\n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                \n",
    "                if n >= top_n_train:\n",
    "                    accuracy.append(len(set(actual_tags).intersection(tags)) / len(set(actual_tags).union(tags)))\n",
    "                self._loss.append(sample_loss)\n",
    "                n += 1\n",
    "                \n",
    "        return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb358b4f7154ff2908f739aba049a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac95205240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "\n",
    "Ответ: 3, $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
